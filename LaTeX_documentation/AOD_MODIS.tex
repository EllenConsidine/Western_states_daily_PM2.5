\subsection{MODIS AOD}

\subsubsection*{Data Source}

\begin{itemize}[nolistsep]
\item \textbf{Contact}
\item \textbf{Citation/Link}
\item \textbf{Data (local)}
\item \textbf{Geographic Extent}
\item \textbf{Temporal Extent}
\item \textbf{Acknowledgment}
\end{itemize}

\subsubsection*{Brief Description}

We will use AOD estimates from the Deep Blue retrieval algorithm for AOD from the MODIS instrument on the NASA Terra and Aqua satellites (MOD04\_L2 and MYD04\_L2) \citep{Sayer2013}. The MODIS product is available twice daily at a 10 km spatial resolution for cloud-free scenes and is available longer than our 2008-2014  study period 
\citep{MODISMOD04L22017,MODISMYD04L22017}.  

AOD products use cloud filtering algorithms that often remove pixels in the center of the smoke plumes because they are assumed to be clouds due to high reflectivity \citep{kondragunta_revisions_2009}. Given that these can be in the middle of smoke plumes, often the locations most heavily impacted by smoke have missing data for a key variable, AOD. In our previous work in summer in California when rain clouds are incredibly rare, we could be confident that missing values not along the coast were not clouds. However, for this larger study region and time period, this will be a bigger challenge. We will attempt to isolate smoke plumes from true clouds using satellite imagery and smoke plume polygons from NOAA's Hazard Mapping System Fire Smoke Product  \citep{NOAAHazMap2017}. We will then estimate missing values within validated smoke plumes, but not within clouds, using radial basis functions as was done in our previous work \citep{Reid2015}. Radial basis functions are exact interpolation functions that will return observed AOD values where they exist but can interpolate higher values than nearby observations in missing locations, which is needed since the missing values were removed due to their high reflectivity \citep{Reid2015}.


\subsubsection*{Notes}

\subsubsection*{File Format} .hdf

\subsubsection*{Data Filtering and Processing}

\subsubsection*{Final Variable(s)}

\subsubsection*{Methods}

\begin{enumerate}
\item \underline{Step 1: Download the MODIS AOD data sets from both Terra and Aqua sensors:}\\\\
Using the \href{https://search.earthdata.nasa.gov/search?q=MOD04&ok=MOD04}{NASA EarthData online search tool}, search for the 'MOD04' (Terra) data set. Set temporal extent by drawing polygon and set spatial extent by adjusting the appropriate filter on the web interface. Select the collection and proceed to download data. For data download options, specify "Stage for Delivery" through the "FTPPull" distribution option. Specify the email address for orders to be sent to. Orders will be sent to your email with instructions on how to connect to the FTP server and pull the ordered data into your local workspace through the command line. Because the amount of data being requested is large, the orders will come through several separate emails. Repeat this step for the 'MYD04' (Aqua) data set. All of the raw downloaded data from this step will be in .hdf file format.
\item  \underline{Step 2: Set up file system for data processing:}\\\\ 
Create a directory locally named `collected\_data`. In this directory, make two child directories named "MOD04\_terra" and "MYD04\_aqua". Follow instructions in email to download data through FTP into the appropriate MODIS directory (`MOD04\_terra` or `MYD04\_aqua`) depending on whether the order is from the Terra or Aqua sensor.
\item \underline{Step 3: Extract lat, long, and aod values from .hdf files and save into .csv files}\\\\
Run script `modis\_aod\_create\_csv\_file.py`. This script will take all the .hdf files that you have downloaded and store the lat, long and aod value for non-null pixels from the `Deep\_Blue\_Aerosol\_Optical\_Depth\_550\_Land\_Best\_Estimate` SDS. A .csv file will be created for each corresponding .hdf file.
\item \underline{Step 4: Create .shp file for each .csv file}\\\\
Run `modis\_aod\_convert\_csv\_to\_shapefile.py`. This script will read in the .csv files and convert them to .shp files using multiprocessing, which speeds up the process.

\item \underline{Step 5: Project .shp files to US Albers Equal Area Conic}\\\\
Run `modis\_aod\_project\_to\_albers.py`. This script will reproject the .shp files to be US Albers Equal Area Conic (ESRI:102003).

\item \underline{Step 6: Combine .shp files for same date and convert to raster with 10km resolution}\\\\
Run `modis\_aod\_create\_daily\_averages.py`. This will combine all .shp files from the same date and then produce a raster for each with a 10km resolution. Then, the interpolated grids are clipped to the 11 western states (our study area) with a 100km buffer.

\item \underline{Step 7: Extract MODIS AOD value at EPA monitor locations}\\\\
Using ExtractValuesToPoints tool in ArcGIS.

\end{enumerate}

\subsubsection*{Quality Control}

\subsubsection*{Script Names}

\begin{enumerate}
\item modis\_aod\_create\_csv\_file.py
\item modis\_aod\_add\_utc\_to\_csv.py
\item modis\_aod\_merge\_csv\_files.py
\item modis\_aod\_split\_shapefile\_by\_date.py
\item modis\_aod\_create\_24hr\_daily\_averages.py
\end{enumerate}

\subsubsection*{Data File Names}

\begin{enumerate}
\item n/a
\end{enumerate}