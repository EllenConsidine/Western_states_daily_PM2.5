%\subsection{$\textrm{PM}_{2.5}$ data}%{Compiling Data}

\subsubsection{Processing $\textrm{PM}_{2.5}$ data}

Below are the scripts that process and compile the PM\textsubscript{2.5} data. The ``*'' in each of the file names refers to the current ``processed\_data\_version'' (set in general\_project\_functions.R)  since compiling the data is an ongoing process. 

\begin{enumerate}[nolistsep]
\item \textul{Script1\_Install\_Pkgs.R} >> install packages

\item \textul{Process\_PM25\_data\_step1.R} >> compiles the various PM\textsubscript{2.5} data sources into a single data frame. Data eliminations to the data are:

\begin{enumerate}[nolistsep]
\item EPA: remove states that are not in our study area
\item CARB Mobile :
	\begin{enumerate}[nolistsep]
	\item remove hourly observations that have negative concentrations
	\item remove rows with NA values for Latitude, Longitude, date, PM\textsubscript{2.5}, RHi, Flow, and voltage
	\end{enumerate}
\item DRI:
	\begin{enumerate}[nolistsep]
	\item remove hourly observations that have negative concentrations
	\end{enumerate}
\end{enumerate}

%The only eliminations of data are geographic, to remove states that are not in our study area., 
%and for CARB Mobile, only rows that have non-NA values for Latitude, Longitude, date, PM\textsubscript{2.5}, RHi, Flow, and voltage are processed.

 Update time frame of study if necessary (set in general\_project\_functions.R). The output from this script is a csv file and sink .txt for each  PM\textsubscript{2.5} data source as well as a file with all of the PM\textsubscript{2.5} data sources merged together (``PM25\_Step1\_part\_*.csv''). This script takes about 10 minutes to run on a laptop (3 cores). The script runs in parallel, with each data source sent to a different processor. Output files: %This script creates a main data file as well as a csv of data for each PM2.5 data source and a text file describing the data:

\begin{enumerate}[nolistsep]
\item PM25\_Step1\_part\_*.csv (the main data file)
\item PM25\_CARB\_Step1\_part\_*.csv
\item PM25\_CARB\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_EPA\_Step1\_part\_*.csv
\item PM25\_EPA\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_FireCacheDRI\_Step1\_part\_*.csv
\item PM25\_FireCacheDRI\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_IMPRHR2MF88101\_10010\_Step1\_part\_*.csv
\item PM25\_IMPRHR2MF88101\_10010\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_IMPRHR2RCFM88401\_10010\_Step1\_part\_*.csv
\item PM25\_IMPRHR2RCFM88401\_10010\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_IMPRHR3MF88101\_10006\_Step1\_part\_*.csv
\item PM25\_IMPRHR3MF88101\_10006\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_PCAPS\_Step1\_part\_*.csv
\item PM25\_PCAPS\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_UintahBasin\_Step1\_part\_*.csv
\item PM25\_UintahBasin\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_UtahDEQ\_Step1\_part\_*.csv
\item PM25\_UtahDEQ\_Step1\_part\_*\_combining\_sink.txt
\item PM25\_CARBMobile\_Step1\_part\_*.csv
\item PM25\_CARBMobile\_Step1\_part\_*\_combining\_sink.txt
\item Time series of raw data and map of locations for each data source (writes to estimate-pm25/LaTeX\_documentation/Code\_Outputs/ folder)
\end{enumerate}
\medskip
Notes that are useful when incorporating new data:
\begin{enumerate}
\item Process\_PM25\_data\_step1.R: change n\_data\_sets to higher number if adding new data source
\item For the Federal Land Manager Database (IMPROVE) data: Download data as described in Section \ref{IMPROVE}. Edit ``skip\_n\_files'' in process\_PM25\_parallel\_wrapper\_function.R so that FMLEdata\_Parameter\_MetaData will load the row with the header `DatasetID, Parameter, Code, AQSCode, Units, Description' for each IMPROVE file.
\end{enumerate}

Note about flag added to data:

	\begin{enumerate}
	\item For DRI and CARB Mobile data, put in flags for voltage data outside the range 12.5-14.4 V. This range was suggested by Joseph McCormack at CARB. Flags for relative humidity and flow were also added. Thresholds are defined in the code in general\_project\_functions.R.
	\end{enumerate}

\item \textul{Process\_PM25\_data\_step2.R} >> cleans the data. This script takes about 5 minutes on a laptop. This script outputs the following files: 
	\begin{enumerate}[nolistsep]
	\item PM25\_Step2\_part\_*.csv (main cleaned data file)
	\item PM25\_Step2\_part\_*\_sink.txt (description and summaries of the data at each step of the quality cutting)
	\item PM25\_Step2\_part\_*\_Locations.csv (list of unique locations from main cleaned data file)
	\item PM25\_Step2\_part\_*\_Locations\_Dates.csv (list of unique locations/dates from main cleaned data file)
	\item Data\_Removed\_in\_PM25\_Step2\_part\_*.csv (all data that was removed from the cleaned file and the reason for removal of each data point is indicated)
	\end{enumerate}
The following is a list of the quality cuts and changes made to the data:
	\begin{enumerate}[nolistsep]
	\item Replace ``UNKNOWN'' datum in EPA data with ``NAD27'' per Colleen's advice.
	\item Remove negative and NA PM\textsubscript{2.5} concentrations. This includes removing all data for a monitor on a given day if any of the hourly observations were negative.
	\item For the hourly data, remove monitor-days that do not have at least 18/24 observations.
	%\item For DRI data, remove data with voltage flags (which includes flags that came with the data and flags that were put in because the battery voltage was outside the range 11-17 V.
	\item For DRI and CARB Mobile data, remove data with voltage flags.
	\item For DRI and CARB Mobile data, remove data with flow flags. Different flow thresholds were set for these data sets.
	%\item For DRI data, remove data at or below 0 L/min for flow. Think about whether a minimum value of flow should be set (higher than zero).
	\item for DRI and CARB Mobile data, remove data with humidity flags - \textbf{Still need to clarify with CARB whether RHi is internal or ambient RH. RHi is currently fed into the Relative humidity column in input\_mat, but it might be better to put it in the internal sensor RH. RHi is the variable that should have the threshold, not RHx.} 
	\item June 6, 2014 24-hr average PM\textsubscript{2.5} concentration from monitor ``Smoke NCFS E-BAM \#1'' (Fire\_Cache\_Smoke\_DRI\_Smoke\_NCFS\_E\_BAM\_N1.csv) is 24,203 ug/m3. There's nothing apparent wrong with the hourly data, however, this is the only day of data that made it through the other quality checks from this data file. This suggests that this monitor is suspect, and will be removed.
	\item Remove data points with lat/lon outside this box: (50,-126) to (25,-101). These values are defined in general\_project\_functions.R. %-93) 
	\item Remove data outside the study period (defined in general\_project\_functions.R).
	\item Remove data with ``Event\_Type'' = ``Excluded''
	\item Remove data with more than 0.001 degrees variation in Lat/lon within a day
	\item Remove data from monitor ``USFS R2-265'' (Fire\_Cache\_Smoke\_USFS\_R2-265.csv) between October 2016 - May 2017. The concentrations (some higher than 65,000,000 ug/m3) and the behavior of the concentrations (frequently changing by exactly 1000 ug/m3 from one hour to the next) are unrealistic. The data outside this time frame look more reasonable.
	\item Remove data from monitor ``USFS R2-264'' (Fire\_Cache\_Smoke\_USFS\_R2-264.csv") between October 2016 - October 2017. The behavior of the concentrations (frequently changing by exactly 1000 ug/m3 from one hour to the next) are unrealistic. The data outside this time frame look more reasonable.
	\item Remove data from monitor ``FWS Smoke \#1'' (Fire\_Cache\_Smoke\_DRI\_FWS\_Smoke\_N1.csv) between February 11-14, 2017. The behavior of the concentrations (frequently changing by exactly 1000 ug/m3 from one hour to the next) are unrealistic. The data outside this time frame look more reasonable.
	\item Remove data from monitor ``Smoke \#22'' (Fire\_Cache\_Smoke\_DRI\_Smoke\_22.csv) on June 15, 2012. The behavior of the concentrations (frequently changing by exactly 1000 ug/m3 from one hour to the next) are unrealistic. The data outside this time frame look more reasonable.
	\item Removing data from monitor ``USFS-R2-69'' during August 31, 2016 - September 5, 2016 becuase the concentrations look unrealistic and can shift by more than 10,000 ug/m3 from one hour to the next. The data outside this time frame look more reasonable.
	\item Removing data from monitor ``USFS-R1-307'' during May 4-19, 2015 because the concentrations look unrealistic and can shift by more than 10,000 ug/m3 from one hour to the next. The data outside this time frame look more reasonable.
	\item Removing data from monitor ``Smoke \# 216'' during May 16- June 17, 2018 because the concentrations look unrealistic and are constant at 851 ug/m3 for extended hours at at time. The data outside this time frame look more reasonable.
	\item Removing data from monitor `` Smoke USFS R2-922'' during July 26-28, 2016 because the concentrations look unrealistic and can shift by thousands of ug/m3 from one hour to the next. The data outside this time frame look more reasonable.

\item Remove data from monitor ``ARB 1027'' (ARB 1027 2018 Historical Data.csv) during August 2-9, 2018. Starting late on August 2, 2018, the data values have a constant value through August 9, 2018, which is unrealistic. The data outside this time frame look more reasonable.

	% if the monitor is near a fire, the air temperature could be quite high \item \textbf{To Do} think about making cuts on any unrealistic air temperatures for DRI data
	%seems unnecessary since both are removed \item \textbf{To Do} need to convert missing values that have a -9999 etc to NA value
	%seems unnecessary \item \textbf{To Do} merge "24-HR BLK AVG" and "24 HOUR" data together in Sample Duration variable
	%One site in Maricopa, AZ has some data points with an observation count of 2 and Observation Percent of 200. The data looks fine otherwise, so I'll keep it. %\item \textbf{To Do} figure out why Observation percent has a max value of 200\%
	% this data point was removed with the other quality cuts %\item \textbf{To Do} figure out if max AQI value of 546 is reasonable
	%can't find 20:00 in the wrong columns - maybe those versions were over-written if we downloaded the files again, not sure. %\item \textbf{To Do} Some DRI files looked like they had hour 20:00 data shifted a couple of columns - look into this and fix it.
	%I think I did this in later scripts. %\item \textbf{To Do} Finish filling in Year, month, day information based on date
	%\item \textbf{To Do} look over summary() output and plots of every variable and determine if any other cuts are necessary
	\end{enumerate}

\item \textul{Process\_PM25\_data\_step3.R} >> convert all PM2.5 data to the same datum (NAD83). Take the converted location info and put it into the data frame with the daily PM\textsubscript{2.5} data. This script also rounds all lat/lon info to 5 digits. This script takes several minutes on a laptop. This script also outputs the dates/locations with 7 day lags (used for active fire points data extraction). This script outputs these files:

\begin{enumerate}[nolistsep]
\item PM25\_Step3\_part\_*\_NAD83.csv (main data file)
\item PM25\_Step3\_part\_*\_Locations\_NAD83\_include\_old\_projection.csv
\item PM25\_Step3\_part\_*\_Locations\_NAD83.csv
\item PM25\_Step3\_part\_*\_Locations\_Dates\_NAD83\_include\_old\_projection.csv
\item PM25\_Step3\_part\_*\_Locations\_Dates\_NAD83.csv
\item PM25\_Step3\_part\_*\_Locations\_Dates\_NAD83\_wLags.csv
\end{enumerate}

%\item \textul{Define\_directories.R} >> (becoming obsolete) clears all variables and defines directories. Needs to be ran between each of the following scripts. (Want to automate this eventually.) When processing a new batch of data, iterate ``processed\_data\_version'' by one letter and create a new subfolder in /home/Processed\_Data/ named PM25\_data\_part\_* where * is the new processed\_data\_version.

\item \textul{Process\_PM25\_data\_step4\_parallel.R} >> composite replicate data and data where there are co-located monitors. This script produces two different versions of the data:   %\textbf{To Do} finish colocated version of code to go with aves version of code.
\begin{enumerate}
\item PM25\_Step4\_part\_*\_de\_duplicated\_aves\_ML\_input.csv takes the averages of all available co-located data
\item PM25\_Step4\_part\_e\_de\_duplicated\_aves\_prioritize\_24hr\_obs\_ML\_input.csv prioritizes data that was originally a 24-hour observation (typically FRM/filter-based measurements) over the data that was an average of hourly observations. 
\end{enumerate}

 Calls these functions:
  \begin{enumerate}
  \item PM25\_station\_deduplicate\_aves\_parallel.fn%Combine\_true\_replicates\_R\_function.R - note that the minimum Observation Percent is kept, not the mean.
  \item PM25\_station\_deduplicate\_aves\_parallel.fn
  \item prioritize\_daily\_obs\_over\_hourly.fn (only called if de\_duplication\_method is set to ``prioritize\_24Hour\_Obs''
  \item fill\_input\_mat\_aves.fn %fill\_in\_aves\_coloc\_unique\_PC\_POC\_MN\_function.R
    \begin{enumerate}
    \item concatinate\_within\_column\_function.R
    \item concatinate\_vector\_of\_strings.fn
    \end{enumerate}

  %\item set\_data\_types\_by\_column\_R\_function.R
  \end{enumerate}
%\item \textul{Plot\_ML\_Input\_File.R} >> create plots, maps, and statistical summary - needs to be changed to take input from De-duplicate code instead of file from Create\_ML\_Input\_File.R
%\item \textbf{to be written} >> merge with satelite and other data
\item \textul{Process\_PM25\_data\_create\_report.R} >> map locations of monitors by data source/year

%separate part a locations from part b, etc - to be used for extracting predictor variables to points of monitor locations and points of interest for predicting PM2.5

%\item \textul{write\_shp.py} given listing of all PM2.5 monitor locations (in different datums), write each datum into a different shapefile
%\item \textul{reproject\_shp.py} project all shapefiles into US Equal Area Albers (ESRI 102003); save coordinates
%\item \textul{reproject\_shp\_2.py} transform all original shapefiles into NAD83 datum (ESRI 4269); save coordinates 
%\item \textul{merge\_shp.py} merge all the shapefiles into one
%\item \textul{join\_coordinates.py} combine the geographic coordinates and projection coordinates and write to one CSV

%\item \textul{Process\_PM25\_data\_step5.R} >> script to take the reprojected location info and put it into the data frame with the daily PM\textsubscript{2.5} data. %\textul{Merge\_reprojections\_ML\_Input\_File.R}

\end{enumerate}
% {DeDuplicate\_ML\_Input\_File\_v2.R}

\subsubsection{Determine which dates/locations are new to most recent ``processed\_data\_version'' }

See Merging\_loc\_dates.R

%\textul{Separate\_Locations\_Dates\_by\_processed\_data\_version.R} >> Take difference between parts d and b to find what locations/dates are only in part d. This script takes a few minutes on a laptop. 

\begin{enumerate}[nolistsep]
\item part a: early version created while writing code. Disregard.
\item part b: first batch of PM2.5 data that was used to extract predictor data, years 2008-2014
\item part c: county centroids, 2008-2014. This work flow has now been moved to the ``Locations\_of\_interest''.
\item part d: second batch of PM2.5 data, adds AQS data for 2015-2018.
\item part e: updates IMPROVE and Fire Cache data to include 2008-2018 (whatever portion of that was available for download)
\item part f: add 37 mobile monitors from CARB (2013-2018), add more data from Fire Cache Data, EPA, CARB, UT DEQ, %Uintah Basin
\end{enumerate}

\subsubsection{Notes about very high data points}

Only one data point with concentrations above 1000 ug/m3 made it through all of the quality checks:

%All files with daily average concentrations above 1000 ug/m3 were individually inspected. The following Fire Cache monitors have concentrations above 1000 ug/m3 and were kept because the file looked ok (at least there was nothing obviously wrong). (Some files shifted hourly concentrations in increments of 1000 ug/m3 and those were removed as described in Step 2 above.)
\begin{enumerate}[nolistsep]
%\item RSF Smoke Monitor 1 (1087.526 ug/m3 on 2016-06-08) 
%\item Smoke \#16 (1825.333 ug/m3 on 2015-09-10)
%\item Three monitors observed concentrations above 1000 ug/m3 during September 2-7, 2017:
%	\begin{enumerate}[nolistsep]
%\item Smoke 215 (2661.652 ug/m3 on 2017-09-07)
%\item Smoke 216 (1440.217 ug/m3 on 2017-09-02 and 1100.083 ug/m3 on 2017-09-03)
%\item ARB 1021  (1155.875 ug/m3 2017-09-03 )
%	\end{enumerate}
\item ARB 1013 (1013.250 ug/m3 on 2018-11-14)
\end{enumerate}

