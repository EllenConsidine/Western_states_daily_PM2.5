\subsection{Meteorological Data}
\subsubsection*{Data Source} NCEP North American Regional Reanalysis (NARR) from NCAR
\begin{itemize}[nolistsep]
\item \textbf{Contact} Chi-Fan Shih, chifan@ucar.edu
\item \textbf{Citation/Link} \url{https://rda.ucar.edu}, \url{https://rda.ucar.edu/datasets/ds608.0/}
\item \textbf{Data (local)} May 10, 2018
\item \textbf{Geographic Extent}
\item \textbf{Temporal Extent}
\item \textbf{Acknowledgment}
\end{itemize}
\subsubsection*{Brief Description}

We will obtain meteorological data from the National Centers for Environmental Prediction (NCEP) North American Regional Reanalysis (NARR) \citep{Mesinger2006,NCEPReanalysis2005} because it includes all of the standard meteorological variables but also has planetary boundary layer height, which has proved to be an important variable for converting AOD to PM\textsubscript{2.5} \citep{liu_estimating_2005}. We will calculate 24-hour averages from 3-hourly data for temperature, relative humidity, sea level pressure, surface pressure, planetary boundary layer height, dew point temperature, precipitation, and the U and V components of wind speed. NARR has 32 km resolution and is available from 1979 onward. 

\subsubsection*{Notes}

We contacted Chi-Fan Shih at NCAR. She emailed us a link to the requested data (link is only valid for 11 days). The data is 28.31 G, and the website provides a few options for how to download the data. We chose the ``Perl download script'' button, which generates a short perl script specific to the requested data. To use this, we downloaded Perl \url{http://strawberryperl.com/} (see also \url{https://www.perl.org/}). The generated perl script calls wget( \url{https://www.gnu.org/software/wget/})



\subsubsection*{File Format}

.grb.tar
Resources about this file type: \url{http://www.cpc.ncep.noaa.gov/products/wesley/reading_grib.html}, 


\begin{enumerate}
\item download .grb.tar files (requested from Chi-Fan Shih, who sent a link that was good for about 2 weeks)

\item untar files. The files came as yyyy.grb.tar where yyyy are years 2008-2014. To un-tar the files, open GitBash, and type: tar -xvf 2008.grb.tar This will create a folder called 2008 with many .grb files. Repeat for the other years. See also \url{https://labcit.ligo.caltech.edu/~ethrane/Resources/UNIX/}

%\item Download cygwin (windows only) (to be able to compile wgrib2) from \url{https://www.cygwin.com/}. Chose \url{http://mirrors.xmission.com} as the download site (don't think it matters), searched make and then clicked ``Default'' on all the options so they became ``Install'', see \url{https://stackoverflow.com/questions/4825317/cygwin-make-help} and \url{https://stackoverflow.com/questions/17710209/how-to-run-make-from-cygwin-environment}.
%	\begin{enumerate}
%	\item go to \url{https://www.cygwin.com/}
%	\item click on ``setup-x86\_64.exe'', save file, run
%	\item when selecting components, click on Devel then find ``make'' and change ``Skip'' to ``Install'' (or click ``Skip'' so it changes to 4.1-1''
%	\end{enumerate}

%\item download gcc compiler from \url{https://sourceforge.net/projects/mingw-w64/}

%\item download gfortran compiler from \url{http://gcc.gnu.org/wiki/GFortranBinariesWindows}

%\item Download wgrib2 from here: \url{ftp://ftp.cpc.ncep.noaa.gov/wd51we/wgrib2/wgrib2.tgz} Instructions for wgrib2 at \url{http://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/compile_questions.html} indicate the for ``For Windows 10, you can use WSL and the Ubuntu compilers. Use the generic linux instructions '' %(uses cygwin)... need to download gcc compiler
%	\begin{enumerate}
%		\item \url{https://dev.openttdcoop.org/projects/home/wiki/Setting_up_a_Windows_compile_environment_using_WSL}
%	\end{enumerate}

%\item Download wgrib 

%\item alternatively trying to download grads, which may have compiled versions of wgrib and wgrib2 in it \url{http://opengrads.org/} ... didn't work

\item use the earthlab/r-reidgroup docker image, which has wgrib and wgrib2 installed on it.

\item use rNOMADS R package. It looks like the rNOMADS R package can read .grb files \url{https://cran.r-project.org/web/packages/rNOMADS/rNOMADS.pdf}. rNOMADS calls external routines called wgrib2 \url{http://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/} and wgrib \url{http://www.cpc.ncep.noaa.gov/products/wesley/wgrib.html}.

\item \url{ftp://ftp.cpc.ncep.noaa.gov/wd51we/wgrib/readme}

\item \url{https://rda.ucar.edu/docs/formats/grib/gribdoc/pds.html}

\end{enumerate}



\subsubsection*{Data Filtering and Processing}
\subsubsection*{Final Variable(s)}
\subsubsection*{Methods}
\begin{enumerate}
\item 
\item
\end{enumerate}
\subsubsection*{Quality Control}
\subsubsection*{Script Names}
\begin{enumerate}
\item 
\end{enumerate}
\subsubsection*{Data File Names}
\begin{enumerate}
\item 
\end{enumerate} 