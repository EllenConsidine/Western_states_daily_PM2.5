\subsection{Meteorological Data}
%\subsubsection*{Data Source} NCEP North American Regional Reanalysis (NARR) from NCAR
\subsubsection*{Data Source} North American Mesoscale, Analysis (NAM)
\begin{itemize}[nolistsep]
\item \textbf{Contact} %Chi-Fan Shih, chifan@ucar.edu
%\item \textbf{Citation/Link}  \url{https://rda.ucar.edu}, \url{https://rda.ucar.edu/datasets/ds608.0/}.
\item \textbf{Citation/Link} \url{https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/north-american-mesoscale-forecast-system-nam},  \url{https://nomads.ncdc.noaa.gov/data/namanl/}
%\item \textbf{Data (local)} May 10, 2018
\item \textbf{Geographic Extent} North America
\item \textbf{Temporal Extent} Available March, 2004 - present with slight delay
\item \textbf{Acknowledgment}
\end{itemize}
\subsubsection*{Brief Description}

%We will obtain meteorological data from the National Centers for Environmental Prediction (NCEP) North American Regional Reanalysis (NARR) \citep{Mesinger2006,NCEPReanalysis2005} because it includes all of the standard meteorological variables but also has planetary boundary layer height, which has proved to be an important variable for converting AOD to PM\textsubscript{2.5} \citep{liu_estimating_2005}. We will calculate 24-hour averages from 3-hourly data for temperature, relative humidity, sea level pressure, surface pressure, planetary boundary layer height, dew point temperature, precipitation, and the U and V components of wind speed. NARR has 32 km resolution and is available from 1979 onward. 

We will obtain meteorological data from the North American Mesoscale, Analysis (NAM) because it includes all of the standard meteorological variables, including planetary boundary layer height, which has proved to be an important variable for converting AOD to PM\textsubscript{2.5} \citep{liu_estimating_2005}. We will calculate 24-hour averages from 6-hourly data for temperature, relative humidity, sea level pressure, surface pressure, planetary boundary layer height, dew point temperature, precipitation, snow coverage, and the U and V components of wind speed. NAM has 12 km resolution and is available 2004 onward.

\subsubsection*{Notes}

%We contacted Chi-Fan Shih at NCAR. She emailed us a link to the requested data (link is only valid for 11 days). The data is 28.31 G, and the website provides a few options for how to download the data. We chose the ``Perl download script'' button, which generates a short perl script specific to the requested data. To use this, we downloaded Perl \url{http://strawberryperl.com/} (see also \url{https://www.perl.org/}). The generated perl script calls wget( \url{https://www.gnu.org/software/wget/})

\subsubsection*{File Format}

Prior to 2018, the files are in *.grb (``grib1'') format, while 2018 data is in *.grb2 (``grib2'') format.

%.grb.tar
Resources about this file type: 
\begin{itemize}
\item rNOMADS is an R package for accessing grb* files. It is mostly geared for grib2 files. \url{https://cran.r-project.org/web/packages/rNOMADS/rNOMADS.pdf}
\item Explanation of what grib files are: \url{http://www.cpc.ncep.noaa.gov/products/wesley/reading_grib.html}, 
\item wgrib program information: \url{http://www.cpc.ncep.noaa.gov/products/wesley/wgrib.html}
\end{itemize}

%If the resources above are insufficient for accessing the grb files, consider using GrADS: \url{http://www.cpc.ncep.noaa.gov/products/wesley/links_grads.html}

\subsubsection*{Data Filtering and Processing}

\begin{enumerate}

\item Use the earthlab/r-reidgroup docker image, which has wgrib and wgrib \url{http://www.cpc.ncep.noaa.gov/products/wesley/wgrib.html} and wgrib2 \url{http://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/} installed on it.
	\begin{enumerate}
		\item Start EC2-session on AWS (using m5a.xlarge session with 30 GB attached memory)
		\item Install and start the earthlab/r-reidgroup docker image, see \url{https://hub.docker.com/r/earthlab/r-reidgroup/}. See also \url{https://docs.google.com/document/d/1hQdZgbnwwBMACzVvTOqdCPFW_jA27JgyL4EtNyCyVa4/edit?usp=sharing}
	\end{enumerate}

%\item Run ``Define\_directories.R'' before running each of the steps below. (Need to figure out how to automate this.)

\item Process\_NAM\_data\_step1.R reads in locations file and outputs the `*\_NextDay' csv file, %Locations\_Dates\_of\_PM25\_Obs\_DeDuplicate.csv and outputs Locations\_Dates\_of\_PM25\_Obs\_DeDuplicate\_wNextDay.csv, 
which includes the next day for each location/day listed in the first file. The purpose of this is so all of the necessary NAM files can be processed. UTC dates can go into the next day for western US time zones. This script runs in serial and takes approximately 6 minutes to run. This step uses these input files and R packages and functions:
	\begin{enumerate}
	\item Input files:
		\begin{enumerate}
		\item PM25\_Step3\_part\_*\_Locations\_Dates\_NAD83.csv  %Locations\_Dates\_of\_PM25\_Obs\_DeDuplicate.csv
		\item CountyCentroid\_Locations\_Dates\_2008-01-01to2018-12-31.csv
		\end{enumerate}
	\item Packages:
		\begin{enumerate}
		\item (none)
		\end{enumerate}
	\item Files with custom functions:
		\begin{enumerate}
		\item general\_project\_functions.R %add\_next\_day\_date\_loc\_function.R.
		\item NAM\_processing\_functions.R
		\end{enumerate}
	\item Output files:
		\begin{enumerate}
		\item NAM\_Step1\_part\_*\_Locations\_Dates\_PM25\_Locations\_Dates\_wNextDay.csv
		\item NAM\_Step1\_part\_e\_Locations\_Dates\_CountyCentroid\_wNextDay.csv
		\end{enumerate}
	\end{enumerate}
	
\item Process\_NAM\_data\_step2\_parallel.R downloads each NAM file, extracts relevant data, and deletes the original NAM data. (All of the NAM files together would be about 1.6 Tb.) This file operates in parallel, and will use n-1 cores, where n is the number of cores on the computer. The output is 1 csv with all locations of interest for a given date and time step. The time steps for the NAM are 0Z, 6Z, 12Z, and 18Z. The output files have the format Locations\_Dates\_of\_PM25\_Obs\_DeDuplicate\_YYYY\_MM\_DD\_XXUTC.csv where XX refers the to the timestep. Change the study start and stop dates for the dates to be processed. This step uses these input files and R packages and functions:
\begin{enumerate}
	\item Input files:
		\begin{enumerate}
		\item NAM\_Step1\_part\_*\_Locations\_Dates\_PM25\_Locations\_Dates\_wNextDay.csv
		\item NAM\_Step1\_part\_e\_Locations\_Dates\_CountyCentroid\_wNextDay.csv
		\end{enumerate}
	\item Packages:
		\begin{enumerate}
		\item rNOMADS
		\item parallel
		\end{enumerate}
	\item Files with custom functions:
		\begin{enumerate}
		\item general\_project\_functions.R 
		\item NAM\_processing\_functions.R
		\item extract\_NAM\_data\_parallel\_function.R
		\item define\_project\_bounds\_function.R
		\item loop\_NAM\_run\_times.parallel\_function.R
		\item merging\_data\_functions.R
		\end{enumerate}
	\item Output files:
		\begin{enumerate}
		\item 
		\item 
		\end{enumerate}
	\end{enumerate}


	\begin{enumerate}
	\item Locations\_Dates\_of\_PM25\_Obs\_DeDuplicate.csv - Data file with dates (local) and locations where you want the NAM data
	\item MeteoVariablesNAM.csv - listing of meteorological variables to be extracted from NAM data
	\item rNOMADS R package (which calls wgrib and wgrib2) \url{https://cran.r-project.org/web/packages/rNOMADS/rNOMADS.pdf}
	\item parallel R package
	\item grb1to2\_conversion\_prep\_function.R - This script downloads the files that will be necessary to run grb1to2.pl, created by the Climate Prediction Center \url{http://www.cpc.ncep.noaa.gov/products/wesley/grb1to2.html}
	\item loop\_NAM\_run\_times.parallel\_function.R - this function loops through the time steps on a given day and calls function (listed below) to extract meteo data at locations of interest
	\item define\_project\_bounds\_function.R - the bounding box for the study area is defined in this function. The scripts can run faster if the entire NAM domain does not need to be loaded into memory.
	\item extract\_NAM\_data\_parallel\_function.R - this function extracts the NAM data at points of interest
	\item which\_type\_of\_grib\_file\_function.R - this function determines whether the data for a given time step are grib1 or grib2 format
	\item convert\_grib1to2\_function.R - convert file type from grib1 to grib2, unless it's already a grib2 file. This is essentially a wrapper for grb1to2.pl created by the Climate Prediction Center \url{http://www.cpc.ncep.noaa.gov/products/wesley/grb1to2.html}
	\end{enumerate}

\item Process\_NAM\_data\_step3.R merges all of the files from step 2 into a single file and adds a column at the beginning giving the UTC time stamp.

\item Process\_NAM\_data\_step4.R Add time zones and local times. %compiling 24-hr summaries

\item To Do: Merge\_NAM\_times.R will merge the 4 time steps to give a 24-hr summary. Min, max, mean, etc. is set in MeteoVariabesNAM.csv.

%\item download .grb.tar files (requested from Chi-Fan Shih, who sent a link that was good for about 2 weeks)

%\item untar files. The files came as yyyy.grb.tar where yyyy are years 2008-2014. To un-tar the files, open GitBash, and type: tar -xvf 2008.grb.tar This will create a folder called 2008 with many .grb files. Repeat for the other years. See also \url{https://labcit.ligo.caltech.edu/~ethrane/Resources/UNIX/}

%\item Download cygwin (windows only) (to be able to compile wgrib2) from \url{https://www.cygwin.com/}. Chose \url{http://mirrors.xmission.com} as the download site (don't think it matters), searched make and then clicked ``Default'' on all the options so they became ``Install'', see \url{https://stackoverflow.com/questions/4825317/cygwin-make-help} and \url{https://stackoverflow.com/questions/17710209/how-to-run-make-from-cygwin-environment}.
%	\begin{enumerate}
%	\item go to \url{https://www.cygwin.com/}
%	\item click on ``setup-x86\_64.exe'', save file, run
%	\item when selecting components, click on Devel then find ``make'' and change ``Skip'' to ``Install'' (or click ``Skip'' so it changes to 4.1-1''
%	\end{enumerate}

%\item download gcc compiler from \url{https://sourceforge.net/projects/mingw-w64/}

%\item download gfortran compiler from \url{http://gcc.gnu.org/wiki/GFortranBinariesWindows}

%\item Download wgrib2 from here: \url{ftp://ftp.cpc.ncep.noaa.gov/wd51we/wgrib2/wgrib2.tgz} Instructions for wgrib2 at \url{http://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/compile_questions.html} indicate the for ``For Windows 10, you can use WSL and the Ubuntu compilers. Use the generic linux instructions '' %(uses cygwin)... need to download gcc compiler
%	\begin{enumerate}
%		\item \url{https://dev.openttdcoop.org/projects/home/wiki/Setting_up_a_Windows_compile_environment_using_WSL}
%	\end{enumerate}

%\item Download wgrib 

%\item alternatively trying to download grads, which may have compiled versions of wgrib and wgrib2 in it \url{http://opengrads.org/} ... didn't work

%\item use rNOMADS R package. It looks like the rNOMADS R package can read .grb files \url{https://cran.r-project.org/web/packages/rNOMADS/rNOMADS.pdf}. rNOMADS calls external routines called wgrib2 .

%\item \url{ftp://ftp.cpc.ncep.noaa.gov/wd51we/wgrib/readme}

%\item Octet code info: \url{http://www.nco.ncep.noaa.gov/pmb/docs/on388/section1.html}

%\item \url{https://rda.ucar.edu/docs/formats/grib/gribdoc/pds.html}

\end{enumerate}

\subsubsection*{Final Variable(s)}
See MeteoVariablesNAM.csv

%\subsubsection*{Methods}
%\begin{enumerate}
%\item 
%\item
%\end{enumerate}
\subsubsection*{Quality Control}

%\subsubsection*{Script Names}
%\begin{enumerate}
%\item 
%\end{enumerate}
%\subsubsection*{Data File Names}
%\begin{enumerate}
%\item 
%\end{enumerate} 

%\section{North American Mesoscale, Analysis}

%\begin{enumerate}
%\item \url{https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/north-american-mesoscale-forecast-system-nam}

%\end{enumerate}

%\section{GFS}

%\begin{enumerate}
%\item \url{https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs}
%\item 0.5 degree resolution, which is about 55 km %(\url{https://www.vets.ucar.edu/vg/Climate_Model_Resolution%20%20/index.html})

%\end{enumerate}
